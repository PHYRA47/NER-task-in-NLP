{
 "cells": [
  {
   "source": [
    "# Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"d:\\\\School Stuff\\\\SEM_5\\\\Big Data Analysis\\\\科研实践 ——————Research Practice\")\n",
    "data = pd.read_csv(\"practice course/data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1048565</th>\n      <td>Sentence: 47958</td>\n      <td>impact</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048566</th>\n      <td>Sentence: 47958</td>\n      <td>.</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048567</th>\n      <td>Sentence: 47959</td>\n      <td>Indian</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>1048568</th>\n      <td>Sentence: 47959</td>\n      <td>forces</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048569</th>\n      <td>Sentence: 47959</td>\n      <td>said</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>Sentence: 47959</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>Sentence: 47959</td>\n      <td>responded</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>Sentence: 47959</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>Sentence: 47959</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>Sentence: 47959</td>\n      <td>attack</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31152"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "word2idx[\"Obama\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "tag2idx[\"B-geo\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and prepare the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 75)                0         \n_________________________________________________________________\nembedding_1 (Embedding)      (None, 75, 20)            703600    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 75, 100)           28400     \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, 75, 50)            5050      \n_________________________________________________________________\ncrf_1 (CRF)                  (None, 75, 17)            1190      \n=================================================================\nTotal params: 738,240\nTrainable params: 738,240\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      "38846/38846 [==============================] - 91s 2ms/step - loss: 0.1067 - crf_viterbi_accuracy: 0.9678 - val_loss: 0.0316 - val_crf_viterbi_accuracy: 0.9848\n",
      "Epoch 2/5\n",
      "38846/38846 [==============================] - 90s 2ms/step - loss: 0.0122 - crf_viterbi_accuracy: 0.9878 - val_loss: 6.4554e-04 - val_crf_viterbi_accuracy: 0.9880\n",
      "Epoch 3/5\n",
      "38846/38846 [==============================] - 93s 2ms/step - loss: -0.0127 - crf_viterbi_accuracy: 0.9903 - val_loss: -0.0202 - val_crf_viterbi_accuracy: 0.9898\n",
      "Epoch 4/5\n",
      "38846/38846 [==============================] - 90s 2ms/step - loss: -0.0321 - crf_viterbi_accuracy: 0.9913 - val_loss: -0.0379 - val_crf_viterbi_accuracy: 0.9904\n",
      "Epoch 5/5\n",
      "38846/38846 [==============================] - 96s 2ms/step - loss: -0.0500 - crf_viterbi_accuracy: 0.9919 - val_loss: -0.0544 - val_crf_viterbi_accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=5,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1200x1200 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(hist[\"crf_viterbi_accuracy\"])\n",
    "plt.plot(hist[\"val_crf_viterbi_accuracy\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4796/4796 [==============================] - 4s 780us/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_te, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score: 81.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         art       0.00      0.00      0.00        36\n         eve       0.00      0.00      0.00        35\n         geo       0.81      0.89      0.85      3887\n         gpe       0.96      0.93      0.94      1568\n         nat       0.00      0.00      0.00        27\n         org       0.72      0.63      0.67      2017\n         per       0.77      0.76      0.76      1688\n         tim       0.89      0.84      0.87      2020\n\n   micro avg       0.82      0.81      0.82     11278\n   macro avg       0.52      0.51      0.51     11278\nweighted avg       0.82      0.81      0.81     11278\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word           ||True ||Pred\n==============================\nRussia         : B-geo B-geo\n's             : O     O\nstate-run      : O     O\nnatural        : O     O\ngas            : O     O\ncompany        : O     O\n,              : O     O\nGazprom        : B-org B-org\n,              : O     O\ncut            : O     O\noff            : O     O\nexports        : O     O\nto             : O     O\nUkraine        : B-geo B-geo\nSunday         : B-tim B-tim\nafter          : O     O\nKiev           : B-org B-geo\nrefused        : O     O\na              : O     O\ncontract       : O     O\nthat           : O     O\nincreased      : O     O\nthe            : O     O\nprice          : O     O\nby             : O     O\n400            : O     O\npercent        : O     O\n.              : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1928\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_te[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], tags[t], tags[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [\"Hawking\", \"was\", \"a\", \"Fellow\", \"of\", \"the\", \"Royal\", \"Society\", \",\", \"a\", \"lifetime\", \"member\",\n",
    "                 \"of\", \"the\", \"Pontifical\", \"Academy\", \"of\", \"Sciences\", \",\", \"and\", \"a\", \"recipient\", \"of\",\n",
    "                 \"the\", \"Presidential\", \"Medal\", \"of\", \"Freedom\", \",\", \"the\", \"highest\", \"civilian\", \"award\",\n",
    "                 \"in\", \"the\", \"United\", \"States\", \".\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-gpe',\n",
       " 'O',\n",
       " 'I-gpe',\n",
       " 'B-eve',\n",
       " 'I-per',\n",
       " 'I-tim',\n",
       " 'B-org',\n",
       " 'B-geo',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'I-nat',\n",
       " 'B-nat',\n",
       " 'I-eve',\n",
       " 'B-tim',\n",
       " 'I-org',\n",
       " 'I-geo',\n",
       " 'B-per']"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word           ||Prediction\n==============================\nHawking        : O    \nwas            : O    \na              : O    \nFellow         : O    \nof             : O    \nthe            : O    \nRoyal          : B-org\nSociety        : I-org\n,              : O    \na              : O    \nlifetime       : O    \nmember         : O    \nof             : O    \nthe            : O    \nPontifical     : B-org\nAcademy        : I-org\nof             : I-org\nSciences       : I-org\n,              : O    \nand            : O    \na              : O    \nrecipient      : O    \nof             : O    \nthe            : O    \nPresidential   : O    \nMedal          : O    \nof             : O    \nFreedom        : B-org\n,              : O    \nthe            : O    \nhighest        : O    \ncivilian       : O    \naward          : O    \nin             : O    \nthe            : O    \nUnited         : B-geo\nStates         : I-geo\n.              : O    \n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([x_test_sent[0]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "print(30 * \"=\")\n",
    "for w, pred in zip(test_sentence, p[0]):\n",
    "    print(\"{:15}: {:5}\".format(w, tags[pred]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
